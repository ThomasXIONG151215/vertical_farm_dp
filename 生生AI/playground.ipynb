{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "TTF Font file not found: ./fonts/songqy.ttf",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m pdf\u001b[39m.\u001b[39madd_page()\n\u001b[0;32m      8\u001b[0m \u001b[39m# FPDF 模块必须要使用中文字体才能正常把中文写入pdf\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m pdf\u001b[39m.\u001b[39;49madd_font(\u001b[39m'\u001b[39;49m\u001b[39msongqy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m./fonts/songqy.ttf\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     10\u001b[0m pdf\u001b[39m.\u001b[39madd_font(\u001b[39m'\u001b[39m\u001b[39mCharis\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m./fonts/Charis.ttf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m pdf\u001b[39m.\u001b[39madd_font(\u001b[39m'\u001b[39m\u001b[39mszt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m./fonts/szt.ttf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fpdf\\fpdf.py:469\u001b[0m, in \u001b[0;36mFPDF.add_font\u001b[1;34m(self, family, style, fname, uni)\u001b[0m\n\u001b[0;32m    467\u001b[0m     ttffilename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(SYSTEM_TTFONTS, fname)\n\u001b[0;32m    468\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTTF Font file not found: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m fname)\n\u001b[0;32m    470\u001b[0m name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    471\u001b[0m \u001b[39mif\u001b[39;00m FPDF_CACHE_MODE \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: TTF Font file not found: ./fonts/songqy.ttf"
     ]
    }
   ],
   "source": [
    "import xlrd,os\n",
    "from fpdf import FPDF   # 处理pdf\n",
    "pdf = FPDF()\n",
    "pdf.set_title('just for study and communication!')  # 设置pdf 文件属性，不能有中文字符串\n",
    "pdf.set_author('https://www.ted.com')\n",
    "pdf.set_creator(' ')  # 不能有中文字符串\n",
    "pdf.add_page()\n",
    "# FPDF 模块必须要使用中文字体才能正常把中文写入pdf\n",
    "pdf.add_font('songqy', '', './fonts/songqy.ttf', True)\n",
    "pdf.add_font('Charis', '', './fonts/Charis.ttf', True)\n",
    "pdf.add_font('szt', '', './fonts/szt.ttf', True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.add_font('SIMYOU','','ttf/SIMYOU.TTF',uni=True)\n",
    "pdf.set_font('SIMYOU',size=10)\n",
    "pdf.add_page()\n",
    "#pdf.set_font('Arial', 'B', 16)\n",
    "pdf.cell(40, 10, '你好 World!')\n",
    "\n",
    "pdf.output('tuto1.pdf', 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "api = \"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\"\n",
    "serapi = \"e49a7c10888561af955ab5fcf880d3612e7484e28454f43ad8cf5244e48aeda4\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,model=\"gpt-3.5-turbo-0613\",openai_api_key=api)\n",
    "memory = ConversationEntityMemory(llm=llm, return_messages=True)\n",
    "#set birth memory and identity\n",
    "\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}\n",
    "memory.load_memory_variables(_input)\n",
    "memory.save_context(\n",
    "    _input,\n",
    "    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#调用记忆自己的对话-对象历史\n",
    "#memory.load_memory_variables({\"input\": \"What is your name\"})\n",
    "#初始prompt\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is called Farmbotic, it is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know. You are provided with information about entities the Human mentions, if relevant.\n",
    "\n",
    "Relevant entity information:\n",
    "{entities}\n",
    "\n",
    "Conversation:{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['entities', 'history', 'input'], template=template)\n",
    "\n",
    "#对话链应用\n",
    "conversation = ConversationChain(\n",
    "    llm = llm, \n",
    "    verbose = True,\n",
    "    prompt= ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory = ConversationEntityMemory(llm=llm)\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Deven': '', 'Sam': ''}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: Deven & Sam are working on a hackathon project\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to hear! Hackathons are a fantastic way to collaborate and work on innovative projects. Is there anything specific you would like assistance with regarding your hackathon project?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Deven & Sam are working on a hackathon project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.memory.save_context(\n",
    "    inputs={'inputs':\"Who are you\"},\n",
    "    outputs={'output':\"I'm Farmbotic\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deven': 'Deven is currently working on a hackathon project with Sam.',\n",
       " 'Sam': 'Sam is working on a hackathon project with Deven.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Deven': 'Deven is currently working on a hackathon project with Sam.', 'Sam': 'Sam is working on a hackathon project with Deven.', 'Farmbotic': ''}\n",
      "\n",
      "Current conversation:\n",
      "Human: Deven & Sam are working on a hackathon project\n",
      "AI: That's great to hear! Hackathons are a fantastic way to collaborate and work on innovative projects. Is there anything specific you would like assistance with regarding your hackathon project?\n",
      "Human: Who are you\n",
      "AI: I'm Farmbotic\n",
      "Last line:\n",
      "Human: Who are you\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm Farmbotic, an AI language model developed by OpenAI. I'm here to assist you with any questions or tasks you have, including providing information and insights on a wide range of topics. How can I help you today?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Python': 'Python is a popular programming language.'}\n",
      "\n",
      "Current conversation:\n",
      "Human: Deven & Sam are working on a hackathon project\n",
      "AI:  That sounds like a great project! What kind of project are they working on?\n",
      "Human: what do you know about Python in less than 10 words\n",
      "AI: Python is a popular programming language.\n",
      "Last line:\n",
      "Human: what do you know about Python in less than 10 words\n",
      "You:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Python is a popular programming language.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory.chat_message_histories.in_memory import ChatMessageHistory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain, ConversationChain\n",
    "import json\n",
    "from langchain import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo-0301',openai_api_key=api)\n",
    "original_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "original_chain.run('what do you know about Python in less than 10 words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deven': 'Deven is currently working on a hackathon project with Sam.',\n",
       " 'Sam': 'Sam is currently working on a hackathon project with Deven.',\n",
       " 'Python': 'Python is a popular programming language.'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_chain.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Deven & Sam are working on a hackathon project', additional_kwargs={}, example=False),\n",
       " AIMessage(content=' That sounds like a great project! What kind of project are they working on?', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what do you know about Python in less than 10 words', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Python is a popular programming language.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_messages = original_chain.memory.chat_memory.messages\n",
    "extracted_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'human',\n",
       "  'data': {'content': 'Deven & Sam are working on a hackathon project',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'ai',\n",
       "  'data': {'content': ' That sounds like a great project! What kind of project are they working on?',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'human',\n",
       "  'data': {'content': 'what do you know about Python in less than 10 words',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'ai',\n",
       "  'data': {'content': 'Python is a popular programming language.',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingest_to_db = messages_to_dict(extracted_messages)\n",
    "ingest_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(ingest_to_db, open('ingest_to_db.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'human',\n",
       "  'data': {'content': 'Deven & Sam are working on a hackathon project',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'ai',\n",
       "  'data': {'content': ' That sounds like a great project! What kind of project are they working on?',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'human',\n",
       "  'data': {'content': 'what do you know about Python in less than 10 words',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'ai',\n",
       "  'data': {'content': 'Python is a popular programming language.',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_db = open('ingest_to_db.json', 'r').read()\n",
    "json.loads(test_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'human',\n",
       "  'data': {'content': 'Deven & Sam are working on a hackathon project',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'ai',\n",
       "  'data': {'content': ' That sounds like a great project! What kind of project are they working on?',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'human',\n",
       "  'data': {'content': 'what do you know about Python in less than 10 words',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}},\n",
       " {'type': 'ai',\n",
       "  'data': {'content': 'Python is a popular programming language.',\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_from_db = json.loads(json.dumps(ingest_to_db))\n",
    "retrieve_from_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Deven & Sam are working on a hackathon project', additional_kwargs={}, example=False),\n",
       " AIMessage(content=' That sounds like a great project! What kind of project are they working on?', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what do you know about Python in less than 10 words', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Python is a popular programming language.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_messages = messages_from_dict(retrieve_from_db)\n",
    "retrieved_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='Deven & Sam are working on a hackathon project', additional_kwargs={}, example=False), AIMessage(content=' That sounds like a great project! What kind of project are they working on?', additional_kwargs={}, example=False), HumanMessage(content='what do you know about Python in less than 10 words', additional_kwargs={}, example=False), AIMessage(content='Python is a popular programming language.', additional_kwargs={}, example=False)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_chat_history = ChatMessageHistory(messages=retrieved_messages)\n",
    "retrieved_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Deven & Sam are working on a hackathon project', additional_kwargs={}, example=False), AIMessage(content=' That sounds like a great project! What kind of project are they working on?', additional_kwargs={}, example=False), HumanMessage(content='what do you know about Python in less than 10 words', additional_kwargs={}, example=False), AIMessage(content='Python is a popular programming language.', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_memory = ConversationBufferMemory(chat_memory=retrieved_chat_history)\n",
    "retrieved_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
